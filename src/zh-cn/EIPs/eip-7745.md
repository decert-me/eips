---
eip: 7745
title: 二维日志过滤器数据结构
description: 一种高效且适合轻客户端的区块头布隆过滤器替代方案
author: Zsolt Felföldi (@zsfelfoldi)
discussions-to: https://ethereum-magicians.org/t/eip-7745-two-dimensional-log-filter-data-structure/20580
status: Draft
type: Standards Track
category: Core
created: 2024-07-17
---

## 摘要

用一种新的数据结构替代区块头中固定的 2048 位日志事件布隆过滤器，该结构能够适应每个区块中事件数量的变化，并始终保证足够低的误报率。与每个区块的布隆过滤器不同，所提议的结构允许通过仅访问整个数据集的一小部分来搜索特定事件，这也可以通过默克尔证明来验证，使得搜索既高效又适合轻客户端。

作为额外的好处，新结构提供了更精确的潜在命中位置信息（区块号和交易索引），使得搜索者只需查找每个潜在命中的单个收据。

## 动机

布隆过滤器只有在足够稀疏时才有用。随着每个过滤器中事件数量的增加和过滤器位向量中`1`位的密度，误报率迅速上升。在当前存在的过滤器中，每个日志地址和主题设置了 2048 位固定长度中的 3 位，这在开始时导致了足够稀疏的过滤器，但随着区块 gas 限制的增加，误报率很快变得几乎无用。

每个区块头中的过滤器的另一个问题是，搜索事件需要访问所搜索部分的整个头链（每个区块 5-600 字节）。将日志作为共识的一部分的主要目的是能够用较少的数据证明这些事件，并使得与智能合约的无信任交互成为可能，而无需运行完整节点。虽然带有默克尔证明的收据可以证明此类事件的存在（还值得注意的是，自合并以来，信标链的历史状态根结构也允许在不拥有整个头链的情况下证明主块的规范性），但日志过滤器结构可以证明更多此类事件的不存在。所提议的结构使用所提议的常量，允许在区块范围内对所有潜在命中进行无信任证明，所需数据量至少比当前嵌入头中的布隆过滤器少两个数量级。

## 规范

### 术语和定义

- *日志值*：可以是*地址值*或*主题值*。每个`LOG`操作码添加一个*地址值*和 0..4 个*主题值*。*日志值*由 32 字节哈希表示，计算方式为`SHA2("A" + address)`或`SHA2("T" + topic)`
- *日志值索引*：值在全局范围内映射到线性索引空间，每个添加的*日志值*分配一个单调递增的*日志值索引*。*日志值*按 EVM 执行的顺序添加（*地址值*优先，然后是*主题值*），因此在每个区块和每个交易中生成的日志在索引空间中占据一个连续范围，并在每个区块头和交易收据中添加边界标记。
- *日志值指针*：指向索引空间的全局指针，始终指向下一个可用的*日志值索引*，每次添加*日志值*时增加 1。*日志值指针*的实际值存储在每个区块收据和每个区块头中，在添加给定交易/区块中生成的*日志值*后。
- *过滤器映射*：一个`MAP_WIDTH`乘以`MAP_HEIGHT`的映射，旨在帮助在固定的`VALUES_PER_MAP`长度的*日志值索引*空间中搜索*日志值*。每个*日志值*在映射上标记一次。如果多个*日志值*映射到同一位置，可以在同一位置放置多个标记。行以稀疏编码的方式表示为标记所在列索引的列表。*过滤器映射*是索引的，覆盖每个*映射索引*的*日志值索引*范围为`map_index * VALUES_PER_MAP`到`(map_index+1) * VALUES_PER_MAP - 1`。某个*日志值*在特定映射覆盖的范围内的子位置称为*值子索引*，计算方式为`log_value_index % VALUES_PER_MAP`，用于计算标记应放置的*列索引*。过滤器映射经过树哈希处理，并在每个区块头中引用为`log_filter_root`。请注意，在处理一个区块后，最后一个过滤器映射通常覆盖的索引范围尚未完全填充，因此它可能包含少于`VALUES_PER_MAP`个标记，并且可以在后续区块中进一步填充。
- *过滤器纪元*：以一种方式存储在哈希树中的一组过滤器映射，使得可以在单个默克尔多重证明中高效检索具有相同*行索引*的多个相邻*过滤器映射*。每个*纪元索引*覆盖的*映射索引*范围为`epoch_index * MAPS_PER_EPOCH`到`(epoch_index+1) * MAPS_PER_EPOCH - 1`。

### 日志值映射

日志值映射函数`get_row_index`和`get_column_index`接受一个*日志值*及其在线性索引空间中的位置，并返回应放置给定*日志值*标记的*过滤器映射*的位置。

```
def get_row_index(log_value_index, log_value):
    map_index = log_value_index // VALUES_PER_MAP
    epoch_index = map_index // MAPS_PER_EPOCH
    return SHA2(log_value + uint32_to_littleEndian(epoch_index)) % MAP_HEIGHT

def get_column_index(log_value_index, log_value):
    value_subindex = log_value_index % VALUES_PER_MAP
    map_index = log_value_index // VALUES_PER_MAP
    transform_hash = SHA2(log_value + uint32_to_littleEndian(map_index))
    return column_transform(value_subindex, transform_hash)
```

函数`column_transform`对范围`0 .. MAP_WIDTH-1`执行可逆的准随机变换。它可以通过一系列可逆操作（与奇数的模乘法、模加法、二进制异或）实现，其中这些操作的第二个参数来自`transform_hash`的不同部分。

```
def column_transform(value_subindex, transform_hash):
    x = value_subindex
    x = (x + littleEndian_to_uint32(transform_hash[0:4])) % 2**32
    x = (x * (littleEndian_to_uint32(transform_hash[4:8])*2+1)) % 2**32
    x = x ^ littleEndian_to_uint32(transform_hash[8:12]
    x = (x * (littleEndian_to_uint32(transform_hash[12:16])*2+1)) % 2**32
    x = (x + littleEndian_to_uint32(transform_hash[16:20])) % 2**32
    x = (x * (littleEndian_to_uint32(transform_hash[20:24])*2+1)) % 2**32
    x = x ^ littleEndian_to_uint32(transform_hash[24:28]
    x = (x * (littleEndian_to_uint32(transform_hash[28:32])*2+1)) % 2**32
    return x

def reverse_transform(column_index, transform_hash):
    x = column_index
    x = (x * modInverse(littleEndian_to_uint32(transform_hash[28:32])*2+1, 2**32)) % 2**32
    x = x ^ littleEndian_to_uint32(transform_hash[24:28]
    x = (x * modInverse(littleEndian_to_uint32(transform_hash[20:24])*2+1, 2**32)) % 2**32
    x = (x + 2**32 - littleEndian_to_uint32(transform_hash[16:20])) % 2**32
    x = (x * modInverse(littleEndian_to_uint32(transform_hash[12:16])*2+1, 2**32)) % 2**32
    x = x ^ littleEndian_to_uint32(transform_hash[8:12]
    x = (x * modInverse(littleEndian_to_uint32(transform_hash[4:8])*2+1, 2**32)) % 2**32
    x = (x + 2**32 - littleEndian_to_uint32(transform_hash[0:4])) % 2**32
    return x
```

请注意，如果使用不可逆的`column_transform`，搜索者将需要遍历每个映射行和搜索的日志值的整个`VALUES_PER_MAP`范围，并检查结果的`column_index`中是否有标记，指示潜在命中。拥有匹配的`reverse_transform`函数使得可以仅遍历映射行中找到的实际标记，并查看它们是否可以转换回潜在有效的`value_subindex`：

```
def potential_match_index(map_index, column_index, log_value):
    transform_hash = SHA2(log_value + uint32_to_littleEndian(map_index))
    potential_value_subindex = reverse_transform(column_index, transform_hash)
    if potential_value_subindex < VALUES_PER_MAP:
        return map_index * VALUES_PER_MAP + potential_value_subindex
    return -1
```

### 添加和搜索值

为了提高伪代码的可读性，过滤器映射行在此表示为`filter_map_rows[map_index][row_index]`，其中每行是列索引的列表。请注意，这与共识哈希树表示不匹配，后者出于效率原因有所不同（见下文）。

添加由区块生成的*日志值*：

```
def add_block_logs(block):
    for receipt in block.receipts:
        for log in receipt.logs:
            add_log_value(address_value(log.address))
            for topic in log.topics:
                add_log_value(topic_value(topic))
        receipt.log_value_pointer = log_value_pointer
    block.log_value_pointer = log_value_pointer

def add_log_value(log_value):
    map_index = log_value_pointer // VALUES_PER_MAP
    row_index = get_row_index(map_index // MAPS_PER_EPOCH, log_value)
    column_index = get_column_index(log_value_pointer, log_value)
    filter_map_rows[map_index][row_index].append(column_index)
    log_value_pointer += 1

def address_value(address):
    return sha2("A" + address)

def topic_value(topic):
    return sha2("T" + topic)
```

在区块范围内搜索*日志值*：

```
def search_block_range(first_block_number, last_block_number, log_value):
    # convert block number range to log value index range
    first_index = 0
    if first_block_number > 0:
        first_index = canonical_blocks(first_block_number - 1).log_value_pointer
    last_index = canonical_blocks(last_block_number).log_value_pointer - 1
    return search_index_range(first_index, last_index, log_value)

def search_index_range(first_index, last_index, log_value):
    results = []
    # iterate through the filter map range where relevant logs might be marked
    for map_index in range(first_index // VALUES_PER_MAP, last_index // VALUES_PER_MAP):
        # select relevant row and iterate through column indices
        row_index = get_row_index(map_index // MAPS_PER_EPOCH, log_value)
        row = filter_map_rows[map_index][row_index]
        for column_index in row:
            # reverse transform column index and check if it is a potential match
            match_index = potential_match_index(map_index, column_index, log_value)
            if match_index >= first_index and match_index <= last_index:
                # find receipt that generated the reverse transformed log value index
                receipt = receipt_with_index(match_index)
                # check if it actually lists the searched log value
                if receipt != null and receipt_has_value(receipt, log_value):
                    results.append(receipt)
    return results

def receipt_with_index(log_value_index):
    # return first canonical block receipt where receipt.log_value_pointer > log_value_index

def receipt_has_value(receipt, log_value):
    for log in receipt.logs:
        if log_value == address_value(log.address):
            return true
        for topic in log.topics:
            if log_value == topic_value(topic):
                return true
    return false
```

请注意，上述示例伪代码实现了对单个日志值的搜索，但也可以高效地过滤特定地址/主题组合和模式。

### 共识数据格式

#### 区块头

从执行时间戳`FORK_TIMESTAMP`开始，执行客户端必须用两个新字段替换头部模式中的`logs_bloom`字段：`log_filter_root`（过滤器映射哈希树结构的根哈希）和`log_value_pointer`（处理区块后日志值索引空间中的第一个未占用位置）。

因此，头部的结果 RLP 编码为：

```
rlp([
    parent_hash,
    0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347, # ommers hash
    coinbase,
    state_root,
    txs_root,
    receipts_root,
    log_filter_root,
    log_value_pointer,
    0, # difficulty
    number,
    gas_limit,
    gas_used,
    timestamp,
    extradata,
    prev_randao,
    0x0000000000000000, # nonce
    base_fee_per_gas,
    withdrawals_root,
    blob_gas_used,
    excess_blob_gas,
    parent_beacon_block_root,
])
```

#### 收据
在执行时间戳 `FORK_TIMESTAMP` 开始，执行客户端必须用一个新字段 `log_value_pointer` 替换交易收据模式中的 `bloom` 字段（在执行交易后日志值索引空间中的第一个未占用位置）。

因此，收据的结果 RLP 编码为：

```
rlp([
    type,
    post_state,
    status,
    cumulative_gas_used,
    log_value_pointer,
    logs,
])
```

#### 日志过滤器映射

过滤器映射的每一行都编码为一系列小端二进制编码的列索引。根据提议的值 `MAP_WIDTH = 2**32`，这导致简单而高效的编码，作为一系列 4 字节值。由于此列表中条目的顺序不应影响过滤算法，因此为了简化，索引未排序，而是按日志事件的原始顺序简单附加到列表中。在列索引冲突的罕见情况下（两个事件在同一行生成相同的列索引），索引也会被添加两次。这简化了树的内存维护，并允许客户端仅维护树的单个版本，并在必要时轻松回滚事件。

请注意，单个映射的一行中的索引数量可能会有所不同，行的全局平均条目数为 `VALUES_PER_MAP / MAP_HEIGHT`，而上限为 `VALUES_PER_MAP`。尽管这样的列表可以表示为共识哈希目的的 `List[Bytes4, VALUES_PER_MAP]`，但这只会为树哈希此列表增加不必要的复杂性，因为通常需要整个行进行任何有意义的搜索操作。因此，无论其长度如何，行都简单地进行 `SHA2` 哈希，并将哈希存储在共识树格式中。

#### 日志过滤器树

编码映射行的 `SHA2` 哈希存储在 `log_filter_tree` 中，该树被定义为一个 SSZ 二进制默克尔树，结构为向量的向量列表：

```
    log_filter_tree: List[Vector[Vector[Bytes32, MAPS_PER_EPOCH], MAP_HEIGHT], MAX_EPOCH_HISTORY]
```

映射 `map_index` 的行 `row_index` 的哈希存储在 `log_filter_tree[map_index // MAPS_PER_EPOCH][row_index][map_index % MAPS_PER_EPOCH]` 中。纪元子树列表的长度始终与 `log_value_pointer` 直接相关：

```
epoch_count = (log_value_pointer + VALUES_PER_MAP * MAPS_PER_EPOCH - 1) // VALUES_PER_MAP // MAPS_PER_EPOCH
```

当添加新的纪元子树时，应通过用空字符串的 `SHA2` 哈希填充它进行初始化，该字符串是没有标记的映射行的规范编码。

### 提议的常量

- `MAP_WIDTH`: `2**32`
- `MAP_HEIGHT`: `2**12`
- `VALUES_PER_MAP`: `2**16`
- `MAPS_PER_EPOCH`: `2**6`
- `MAX_EPOCH_HISTORY`: `2**24`

## 理由

### 二维映射

当前存在的布隆过滤器将每个区块的日志事件映射到一维位向量中。在这样的向量中搜索需要访问和处理搜索范围内每个区块的整个向量，而实际上只需要这些向量中的少量位。为了实现更高的带宽效率，来自多个区块的日志数据被收集并以二维方式映射，其中由不同日志值生成的过滤器数据被排序到固定数量的行中。在足够长的时间段内（*过滤纪元*），相同的日志值被映射到相同的行索引，使得只访问感兴趣的行成为可能，从而使在长区块范围内对少量值的典型搜索效率提高了多个数量级。

### 日志值索引空间

在每个区块中，会发出不同数量的日志值。除了低效搜索外，按区块固定大小的布隆过滤器的另一个缺点是过滤器利用率的变化，导致某些区块中过度利用的过滤器产生许多假阳性和/或某些区块中浪费性地未充分利用的过滤器。区块 gas 限制也往往在长期内显著变化，因此任何未来的解决方案必须能够适应每个区块的*日志值*数量的变化。

由于提议设计的*过滤器映射*不再与单个区块相关联，而是包含来自多个区块的过滤器数据，因此可以将它们从区块边界中分离，并将固定数量的*日志值*放入每个*过滤器映射*中。通过 `column_transform` 和 `reverse_transform` 实现的水平映射确保搜索返回的潜在命中不仅提供*过滤器映射*的索引，还提供被搜索的*日志值*可能被添加的确切*日志值索引*。由于每个头部和交易收据中添加了 `log_value_pointer` 字段，因此始终可以找到可能添加*日志值*的确切交易和收据，并且覆盖潜在命中的*日志值索引*的规范收据始终证明它是实际命中还是假阳性。

在其自身的线性索引空间上映射*日志值*确保了结构相同的*过滤器映射*的均匀过滤器利用率。与不断变化的自适应过滤器大小的替代方案相比，这种方法大大简化了存储和树哈希方案以及覆盖更长区块范围的默克尔多重证明的构建。它还允许将每个地址和主题值单独映射到连续索引，并实现特定地址/主题模式过滤器。

### 稀疏水平映射

假阳性率取决于映射密度和每个日志值上放置的标记数量。可以估算为 `FALSE_POSITIVE_RATE = (VALUES_PER_MAP * MARKS_PER_VALUE / MAP_WIDTH / MAP_HEIGHT) ** MARKS_PER_VALUE`。提议的数据结构通过选择高 `MAP_WIDTH` 并仅为每个值添加一个标记来实现低假阳性率。另一种选择是对每个日志值使用多个标记和较低的 `MAP_WIDTH`。在固定目标 `FALSE_POSITIVE_RATE` 下，可以按如下方式计算所需的 `MAP_WIDTH`：

```
AVG_MARKS_PER_ROW = VALUES_PER_MAP * MARKS_PER_VALUE / MAP_HEIGHT
MAP_WIDTH = AVG_MARKS_PER_ROW / (FALSE_POSITIVE_RATE ** (1 / MARKS_PER_VALUE))
```

依赖于映射大小和每个值的标记的一个重要因素是数据效率。更宽的映射需要更多的位来编码每个标记，但也允许每个值的标记更少。编码行的一种简单方法是对每个标记列索引进行二进制编码，要求 `ceil(log2(MAP_WIDTH))` 位每个标记。稀疏位向量的接近最佳压缩也被考虑用于比较（此处未详细说明公式）。

```
AVG_BITS_PER_ROW = ceil(log2(MAP_WIDTH)) * AVG_MARKS_PER_ROW
COMPRESSED_AVG_BITS_PER_ROW = (log2(MAP_WIDTH / AVG_MARKS_PER_ROW) + 1.5) * AVG_MARKS_PER_ROW
```

在考虑以下值为常量的情况下，数据效率取决于 `MARKS_PER_VALUE` 如下：

```
VALUES_PER_MAP = 2**16
MAP_HEIGHT = 2**12
FALSE_POSITIVE_RATE = 1 / 2**28
```

| MARKS_PER_VALUE | MAP_WIDTH | AVG_BITS_PER_ROW | COMPRESSED_AVG_BITS_PER_ROW |
|-----------------|-----------|------------------|-----------------------------|
|1                |2**32      |512               |472                          |
|2                |2**19      |608               |496                          |
|3                |30964      |720               |520                          |
|4                |2**13      |832               |544                          |

这表明，单个标记索引的小型编码几乎可以抵消标记数量的增加，但当考虑过滤器数据集的总大小时，`MARKS_PER_VALUE = 1` 仍然导致最佳的数据效率。如果考虑在搜索特定值时需要访问的数据量，稀疏行的优势更为明显，因为这需要访问 `MARKS_PER_VALUE` 行并将其相互匹配。

### 哈希树结构
哈希树结构和参数是在两种成本之间的权衡下确定的：在长范围的*过滤映射*中搜索*日志值*的带宽成本，以及在处理区块后更新该结构的规范哈希树的处理/内存成本，并添加新的*日志值*。这种权衡存在是因为证明或修改默克尔树的多个叶节点在这些节点彼此靠近时更为高效。

搜索特定的*日志值*需要访问一个给定的行索引，该索引是作为被搜索值和纪元的函数计算的，这意味着在每个纪元中，连续的过滤映射的相同行索引被访问。二维树的行主索引（`log_filter_tree[row_index][map_index]`）将这些行放在一起，从而允许对整个纪元进行高效的默克尔多重证明，该证明在`row_index`路径上仅包含 12 个兄弟节点，在`map_index`路径上包含 24 个节点，以及实际的过滤行。

另一方面，在区块处理期间添加的*日志值*通常放置在许多不同的行中，但占据一个连续的*日志值索引*范围，在大多数情况下落入单个*过滤映射*的范围内。列主索引（`log_filter_tree[map_index][row_index]`）将同一过滤映射的所有行放在一起，确保在区块处理期间通常只需要重新哈希属于单个*过滤映射*的子树及其`map_index`路径。

为了在这两个方面都实现良好的性能，`log_filter_tree`选择了一种第三种混合索引顺序的方法，将`map_index`分为两部分，`epoch_index = map_index // MAPS_PER_EPOCH`和`map_subindex = map_index % MAPS_PER_EPOCH`，并将树索引为`log_filter_tree[epoch_index][row_index][map_subindex]`。这种方法允许像行主顺序那样对整个纪元进行高效的默克尔证明，并且在证明多个纪元时实际上表现得更好，因为昂贵的`epoch_index`路径只需证明一次，而不是每个纪元一次。树更新哈希成本高于列主顺序的情况，因为它还需要更新每个更新行的`map_subindex`路径。然而，下面的计算显示，额外的成本显著小于行主顺序的情况，后者必须为每个更新行更新整个`map_index`路径。

以下计算基于提议的常量：

|**名称**                    |**公式**                                 |**值** |
|----------------------------|--------------------------------------------|----------|
| `epoch_index`路径长度     | `log2(MAX_EPOCH_HISTORY)`                  | 24 hashes|
| `map_subindex`路径长度    | `log2(MAPS_PER_EPOCH)`                     | 6 hashes |
| `map_index`路径长度       | `log2(MAX_EPOCH_HISTORY * MAPS_PER_EPOCH)` | 30 hashes|
| `row_index`路径长度       | `log2(MAP_HEIGHT)`                         | 12 hashes|
| 平均行长度                 | `AVG_BITS_PER_ROW / 8`                     | 64 bytes |

默克尔证明大小估计了三种不同搜索范围长度：单个映射、一个纪元和 64 个纪元。请注意，二进制默克尔树的叶子是实际行的哈希，但证明包含实际行数据，其大小各不相同。对于这些计算，使用了平均行长度。

|**索引顺序**|**1 个映射**            |**1 个纪元**                   |**64 个纪元**                      |
|------------------|---------------------|------------------------------|-----------------------------------|
|列主              |(30+12)\*32+64 = 1408|24\*32+64\*(12\*32+64) = 29440|18\*32+4096\*(12\*32+64) = 1835584 |
|行主              |(30+12)\*32+64 = 1408|(12+24)\*32+64\*64 = 5248     |64\*((12+24)\*32+64\*64) = 335872  |
|混合顺序          |(30+12)\*32+64 = 1408|(24+12)\*32+64\*64 = 5248     |18\*32+64\*(12\*32+64\*64) = 287296|

树更新成本估计为每个额外*日志值*在更新树节点和哈希数据量（包括实际行数据）方面的最坏情况边际成本。请注意，这里假设所有更新的行属于一个或两个*过滤映射*，因此通向这些*过滤映射*的更新树节点是一个可忽略的一次性成本。同样需要注意的是，就像上面的计算一样，使用了平均编码行数据长度来估计哈希数据量。

|**索引顺序**|**更新节点**|**哈希字节**|
|------------------|-----------------|----------------|
|列主              |12               |12\*64+64 = 832 |
|行主              |30+12 = 42       |42\*64+64 = 2752|
|混合顺序          |12+6 = 18        |18\*64+64 = 1216|

## 向后兼容性

现有的日志过滤 API（`eth_getLogs`、`eth_newFilter`、`eth_getFilterLogs`、`eth_getFilterChanges`）可以使用新的过滤数据结构实现。依赖于此 API 的应用程序可以在不进行任何更改的情况下运行，并且性能更高。EVM 不会受到任何影响。

## 测试用例

<!-- TODO -->

## 参考实现

<!-- TODO -->

## 安全考虑

### 与远程证明者的安全访问

为了在远程证明者的帮助下无信任地访问相关数据，证明者需要

- 通过编号证明规范执行头，以确定属于被搜索区块编号范围的*日志值索引*范围
- 根据映射索引和行索引证明过滤映射的相关行
- 通过来自规范执行头的默克尔证明证明单个交易收据，基于潜在匹配的*日志值索引*

过滤映射的相关部分可以通过来自最新执行头的`log_filter_root`进行 SSZ 多重证明。证明规范执行头需要一个规范的信标头，从中可以通过`state_roots`和`historical_summary`结构证明任何信标状态根，从而可以证明属于的执行区块哈希。总之，任何与远程证明者的搜索都与客户端对最近规范信标头的知识一样安全。

### 假阳性

从过滤映射中可以推导出任何区块范围和日志值或日志值模式的一组*潜在匹配*。覆盖潜在匹配的*日志值索引*的规范交易收据可以证明它是否是实际匹配或假阳性。设计保证潜在匹配的集合包括所有实际匹配，但还应确保过多的假阳性不会使搜索的带宽和处理成本过高。

假阳性可能发生在`reverse_transform(column_index, transform_hash)`给出一个有效的`potential_value_subindex`，该值小于`VALUES_PER_MAP`，而`column_index`实际上是由`column_transform(value_subindex, another_transform_hash)`生成的，其中`another_transform_hash`属于不同的日志值。通过假设列索引的随机均匀分布，可以估计每个映射行中的假阳性概率为`VALUES_PER_MAP / MAP_WIDTH = 1 / 2**16`。由于每个映射最多包含`VALUES_PER_MAP`个标记，通过假设行索引的随机均匀分布，可以估计每个映射的假阳性率为`VALUES_PER_MAP^2 / MAP_WIDTH / MAP_HEIGHT = 1 / 2**12`，或每个单独日志值的假阳性率为`VALUES_PER_MAP / MAP_WIDTH / MAP_HEIGHT = 1 / 2**28`。假设每个区块有`2**11`个日志值，这给出了每`2**17`个区块一个假阳性的比率。
尽管某些日志值的使用频率可能远高于其他值，因此行索引分布可能并不完全均匀，但每个*_filter epoch_* 更改行映射确保即使是非常常用的日志值也不会在长期内提高某些其他日志值的误报率。对某个重要日志值（在这种情况下是地址值，因为主题值可以被任何人自由使用）进行故意攻击以提高其误报率的可能性不能完全排除，因为对于每个日志值生成的过滤数据量较少时，总是有可能“挖掘”出另一个生成冲突过滤数据的值。然而，稀疏的准随机水平映射使得这种攻击变得更加困难，因为列索引依赖于日志值和确切的日志值索引，这使得这种攻击仅对区块创建者可能有效，他们可能会因更有利可图的交易集操纵而获得 MEV 奖励。

## 版权

版权及相关权利通过 [CC0](../LICENSE.md) 放弃。